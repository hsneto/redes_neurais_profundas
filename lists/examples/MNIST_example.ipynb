{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST_example.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"_8yiHUBfsqK0","colab_type":"text"},"cell_type":"markdown","source":["# Convolutional Neural Network\n","\n","[A Guide to TF Layers: Building a Convolutional Neural Network](https://www.tensorflow.org/tutorials/layers)\n","\n","Let's build a model to classify the images in the MNIST dataset using the following CNN architecture:\n","\n","> **1. Convolutional Layer #1:** Applies 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function \n","\n","> **2.Pooling Layer #1:** Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n","\n","> **3. Convolutional Layer #2:** Applies 64 5x5 filters, with ReLU activation function\n","\n","> **4. Pooling Layer #2:** Again, performs max pooling with a 2x2 filter and stride of 2\n","\n","> **5. Dense Layer #1:** 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 that any given element will be dropped during training)\n","\n","> **6. Dense Layer #2 (Logits Layer):** 10 neurons, one for each digit target class (0â€“9).\n"]},{"metadata":{"id":"j722NFBosqK1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","# Imports\n","import numpy as np\n","import tensorflow as tf\n","\n","tf.logging.set_verbosity(tf.logging.INFO)\n","\n","# Our application logic will be added here\n","\n","# if __name__ == \"__main__\":\n","#   tf.app.run()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tE8h4qv4sqK5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def cnn_model_fn(features, labels, mode):\n","  '''Model funcion for CNN'''\n","  # Input Layer\n","  input_layer = tf.reshape(features['x'], [-1,28,28,1])\n","  \n","  # Convolutional Layer #1\n","  conv1 = tf.layers.conv2d(inputs=input_layer, \n","                           filters=32, \n","                           kernel_size=[5,5], \n","                           padding='same', \n","                           activation=tf.nn.relu)\n","  \n","  # Pooling Layer #1\n","  pool1 = tf.layers.max_pooling2d(inputs=conv1, \n","                                  pool_size=[2,2], \n","                                  strides=2)\n","  \n","  # Convolutional Layer #2 and Pooling Layer #2\n","  conv2 = tf.layers.conv2d(\n","      inputs=pool1,\n","      filters=64,\n","      kernel_size=[5, 5],\n","      padding=\"same\",\n","      activation=tf.nn.relu)\n","  \n","  pool2 = tf.layers.max_pooling2d(inputs=conv2, \n","                                  pool_size=[2, 2], \n","                                  strides=2)\n","  \n","  # Dense Layer\n","  pool2_flat = tf.reshape(pool2, [-1,7*7*64])\n","  dense = tf.layers.dense(inputs=pool2_flat, \n","                          units=1024, \n","                          activation=tf.nn.relu)\n","  dropout = tf.layers.dropout(inputs=dense, \n","                              rate=0.4, \n","                              training=mode == tf.estimator.ModeKeys.TRAIN)\n","  \n","  # Logits Layer\n","  logits = tf.layers.dense(inputs=dropout, \n","                           units=10)\n","  \n","  predictions = {\n","    # Generate predictions (for PREDICT and EVAL mode)\n","    'classes': tf.argmax(input=logits, axis=1),\n","    # Add 'softmax_tensor_ to the graph. It is used for PREDICT and by 'logging_hook'.\n","    'probabilities': tf.nn.softmax(logits, name=\"softmax_tensor\")\n","  }\n","  \n","  if mode == tf.estimator.ModeKeys.PREDICT:\n","    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n","  \n","  # Calculate Loss (for both, TRAIN and EVAL modes)\n","  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n","  \n","  # Configure the Training Op (for TRAIN mode)\n","  if mode == tf.estimator.ModeKeys.TRAIN:\n","    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n","    train_op = optimizer.minimize(\n","      loss=loss, \n","      global_step=tf.train.get_global_step())\n","    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n","  \n","  # Add evaluation metrics (for EVAL mode)\n","  eval_metric_ops = {\n","    'accuracy': tf.metrics.accuracy(\n","          labels=labels, predictions=predictions[\"classes\"])}\n","  return tf.estimator.EstimatorSpec(\n","      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cNPZkJh6sqK6","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def main(unused_argv):\n","  # Load training and eval data\n","  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n","  train_data = mnist.train.images # Returns np.array\n","  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n","  eval_data = mnist.test.images # Returns np.array\n","  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n","  \n","  # Create the Estimator\n","  mnist_classifier = tf.estimator.Estimator(\n","    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n","  \n","  # Set up logging for predictions\n","  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n","  logging_hook = tf.train.LoggingTensorHook(\n","    tensors=tensors_to_log, every_n_iter=50)\n","  \n","  # Train the model\n","  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"x\": train_data},\n","    y=train_labels,\n","    batch_size=100,\n","    num_epochs=None,\n","    shuffle=True)\n","  \n","  mnist_classifier.train(\n","    input_fn=train_input_fn,\n","    steps=20000,\n","    hooks=[logging_hook])\n","  \n","  # Evaluate the model and print results\n","  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n","    x={\"x\": eval_data},\n","    y=eval_labels,\n","    num_epochs=1,\n","    shuffle=False)\n","  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n","  print(eval_results)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5W7J4Lj4Ndu8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import time"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TTrbcaKFsqK8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1448209,"output_embedded_package_id":"17AxN5JJ6bMIRWwsd0k9FjqY5-xz39mhM"},"outputId":"430e8309-8ae2-443a-ff03-f95186ba94df","executionInfo":{"status":"ok","timestamp":1530203319944,"user_tz":180,"elapsed":240805,"user":{"displayName":"Humberto Neto","photoUrl":"//lh4.googleusercontent.com/-srCUfXbZYXc/AAAAAAAAAAI/AAAAAAAAADA/2W9r0vbMnjA/s50-c-k-no/photo.jpg","userId":"107907802952684013889"}}},"cell_type":"code","source":["t1 = time.time()\n","main(0)\n","print(time.time()-t1)"],"execution_count":5}]}